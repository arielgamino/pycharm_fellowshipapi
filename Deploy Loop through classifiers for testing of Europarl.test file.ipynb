{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import pickle\n",
    "import os\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import string\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_elapsed_time():\n",
    "    end = time.time()\n",
    "    elapsed = end - start\n",
    "    m, s = divmod(elapsed, 60)\n",
    "    h, m = divmod(m, 60)\n",
    "    return (\"%d:%02d:%02d\" % (h,m,s))\n",
    "\n",
    "def tokenize_removepuncuation(text):\n",
    "    #words only \n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    return tokenizer.tokenize(text)\n",
    "\n",
    "def get_most_frequent_letters(tokenized_text, number_of_letters):\n",
    "    # get letters and add to alphabet\n",
    "    alphabet_counter = Counter()\n",
    "    [alphabet_counter.update(list(n)) for n in tokenized_text]\n",
    "    most_common = alphabet_counter.most_common(number_of_letters)\n",
    "    most_common_str = \"\"\n",
    "    for l in most_common:\n",
    "        most_common_str += l[0]\n",
    "    most_common_str = most_common_str[:number_of_letters]\n",
    "    return most_common_str\n",
    "\n",
    "def get_most_frequent_ending_of_words(tokenized_text,number_of_characters):\n",
    "    ending_counter = Counter()\n",
    "\n",
    "    for n in tokenized_text:\n",
    "        ending_counter[n[-number_of_characters:]] += 1\n",
    "\n",
    "    most_common = ending_counter.most_common(10)\n",
    "    most_common_list = []\n",
    "    for l in most_common:\n",
    "        most_common_list.append(l)\n",
    "\n",
    "    return most_common_list\n",
    "\n",
    "#this function receives a document and creates a feature based list\n",
    "# Input:\n",
    "#   [(['worda1','worda2,'worda3'],'LANG-A'),\n",
    "#     ['wordb1','wordb2,'wordb3'],'LANG-B'),...]\n",
    "# Ouput:\n",
    "# [('αποφασιστικής': False,\n",
    "#   'Περιφερειακής': True,\n",
    "#   'pontot': False,...),'ru'),...]\n",
    "\n",
    "def document_features_fromwords(document, word_features, number_of_common_letters):\n",
    "    #normalize words\n",
    "    document = [w.lower() for w in document]\n",
    "    document_words = set(document)\n",
    "    features = {}\n",
    "    #Set most common letters as a feature\n",
    "    most_common_letters = get_most_frequent_letters(document_words, number_of_common_letters)\n",
    "    for n in range(2,number_of_common_letters+1):\n",
    "        features['common_letters_'+str(n)] = most_common_letters[:n]\n",
    "    #Set last three letters of words  also as a feature\n",
    "    most_common_ending = get_most_frequent_ending_of_words(document_words, 3)\n",
    "    counter = 0\n",
    "    for n in most_common_ending:\n",
    "        counter += 1\n",
    "        features['common_ending_top_' + str(counter)] = n[0]\n",
    "    # Add word that are part of common words\n",
    "    for word in word_features:\n",
    "        features[word] = (word in document_words)\n",
    "    return features\n",
    "\n",
    "def classify_document(document, classifier,word_features,number_of_common_letters):\n",
    "    return classifier.classify(document_features_fromwords(tokenize_removepuncuation(document),word_features,number_of_common_letters))\n",
    "\n",
    "def test_europarltest_file(eurofile, resultsfile, everyother, classifier,word_features,number_of_common_letters):\n",
    "    #Read test file and classify each sentence in file\n",
    "    positive_ctr = 0\n",
    "    negative_ctr = 0\n",
    "    total_ctr    = 0 \n",
    "    #save results to file for processing\n",
    "    fileout = open(resultsfile,'w')\n",
    "    #columns\n",
    "    fileout.write('predicted, language given, correctly classified?\\n')\n",
    "    \n",
    "    processed_counter = 0\n",
    "    with open(eurofile,'r') as f:\n",
    "        for line in f:\n",
    "            processed_counter +=1\n",
    "            if(processed_counter%everyother==0):\n",
    "                total_ctr += 1\n",
    "                #language is first two letters in line    \n",
    "                language = line[:2]\n",
    "                #sentence is rest, clean up spaces\n",
    "                sentence = line[2:].strip()\n",
    "                #Detect language based on model\n",
    "                language_detected = classify_document(sentence, classifier,word_features,number_of_common_letters)\n",
    "                correctly_classified = language_detected==language\n",
    "                #tally correct and incorrect\n",
    "                if(correctly_classified):\n",
    "                    #correctly classified\n",
    "                    positive_ctr += 1\n",
    "                else:\n",
    "                    #incorrectly classified\n",
    "                    negative_ctr += 1\n",
    "            \n",
    "                fileout.write(language_detected+','+language+','+str(correctly_classified)+'\\n')\n",
    "    fileout.close()\n",
    "    return total_ctr, positive_ctr, negative_ctr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------\n",
      "           Processing:classifier_10000_10_10.pickle\n",
      "        Number of documents: 10000\n",
      " Percentage of common words: 10\n",
      "   Number of common letters: 10.pickle\n",
      "            Total attempted: 21000\n",
      "       Classified correctly: 19649\n",
      "     Classified incorrectly: 1351\n",
      "      Europar test Accuracy: is 93.56666666666666\n",
      "Elapsed time for accuracy testing:0:06:44\n",
      "-------------------------------\n",
      "           Processing:classifier_10000_15_5.pickle\n",
      "        Number of documents: 10000\n",
      " Percentage of common words: 15\n",
      "   Number of common letters: 5.pickle\n",
      "            Total attempted: 21000\n",
      "       Classified correctly: 19203\n",
      "     Classified incorrectly: 1797\n",
      "      Europar test Accuracy: is 91.44285714285715\n",
      "Elapsed time for accuracy testing:0:14:51\n",
      "-------------------------------\n",
      "           Processing:classifier_10000_20_6.pickle\n"
     ]
    }
   ],
   "source": [
    "models_directory = \"models\"\n",
    "\n",
    "#Loop through all models save as pickles and output results\n",
    "for filename in os.listdir(models_directory):\n",
    "    if(\"classifier\" in filename):\n",
    "        start = time.time()\n",
    "        #filename contains number of documents, words, letters\n",
    "        tokens = filename.split(\"_\")\n",
    "        number_of_documents       = tokens[1]\n",
    "        upto_percentage           = tokens[2]\n",
    "        number_of_common_letters  = tokens[3]\n",
    "        upto_percentage_int = int(upto_percentage)\n",
    "        number_of_common_letters_int = int(upto_percentage_int)\n",
    "\n",
    "        #load classifier\n",
    "        classifier = pickle.load( open( models_directory+\"/\"+filename, \"rb\" ) )\n",
    "        #load word_features, letter_features\n",
    "        word_features = pickle.load( open( models_directory+\"/word_features\"+number_of_documents+\"_\"+upto_percentage+\"_\"+number_of_common_letters, \"rb\" ) )\n",
    "        letter_features = pickle.load( open( models_directory+\"/letter_features\"+number_of_documents+\"_\"+upto_percentage+\"_\"+number_of_common_letters, \"rb\" ) )\n",
    "        print(\"-------------------------------\")\n",
    "        print(\"           Processing:\"+filename)\n",
    "        # -------------Step 6-------------\n",
    "        # Classify all sentences in europarl.test and write results to resultsfile\n",
    "        # This is the actual deployment of the classifier against challenge data\n",
    "        europarl_testfile = \"europarl.test\"\n",
    "        results_outfile   = \"europarl_test_classified_attempt_\"+str(number_of_documents)+\"_\"+str(upto_percentage)+\"_\"+str(number_of_common_letters)+\".csv\"\n",
    "        #use for quick testing, to test just a subset of all documents read\n",
    "        #every other 1000 would only classifies every other n document on testfile        \n",
    "        everyother = 1\n",
    "        start = time.time()\n",
    "        total_ctr, positive_ctr, negative_ctr = test_europarltest_file(europarl_testfile, results_outfile, everyother, classifier,word_features,number_of_common_letters_int)\n",
    "        #results\n",
    "        print(\"        Number of documents: \"+number_of_documents)\n",
    "        print(\" Percentage of common words: \"+upto_percentage)\n",
    "        print(\"   Number of common letters: \"+number_of_common_letters)\n",
    "        print(\"            Total attempted: \"+str(total_ctr))\n",
    "        print(\"       Classified correctly: \"+str(positive_ctr))\n",
    "        print(\"     Classified incorrectly: \"+str(negative_ctr))\n",
    "        accuracy = (positive_ctr/total_ctr) * 100\n",
    "        print(\"      Europar test Accuracy: is\",accuracy)\n",
    "        print(\"Elapsed time for accuracy testing:\"+print_elapsed_time())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}